{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Currently pseudo code showing what functions we need\n",
    "Note \"allTickers\" should be read as loop through all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The essentials\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "tickers = pd.read_csv('./Data/Cleaned_Data/Ticker_library.csv')['Ticker'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.krista_lib as news\n",
    "# News Handling\n",
    "News_allTickers = [news.form_df(ticker) for ticker in tickers] #or read already created csv\n",
    "#Append list into one DF should be ['Ticker','Date','Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.reddit as red\n",
    "# Reddit Handling\n",
    "Reddit_allTickers = [red.pull_all_about(ticker,from_subreddits=['subredditList']) for ticker in tickers] #or read already created csv\n",
    "#Append list into one DF should be ['BusinessMentioned','Date','Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libs.sec as sec\n",
    "# SEC Handling\n",
    "SEC_allTickers = pd.read_csv('.\\Data\\Cleaned_Data\\sec_df.csv') #it is definately too big to do on the fly\n",
    "#DF should be ['Ticker','Date','Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precessing (uses binning, vadar, and tokenizer code)\n",
    "import libs.df_helper as dfh\n",
    "News_vadar = dfh.vadar_time_Bin(News_allTickers,days=7) # Returns a df with headers ['Ticker','time bin','avg vader score of all in bin']\n",
    "Reddit_vadar = dfh.vadar_time_Bin(Reddit_allTickers,days=7) # Returns a df with headers ['Ticker','time bin','avg vader score of all in bin']\n",
    "SEC_vadar = dfh.vadar_time_Bin(SEC_allTickers,days=45) # Returns a df with headers ['Ticker','time bin','avg vader score of all in bin']\n",
    "\n",
    "working_DF = dfh.combiner(News_vadar,Reddit_vadar,SEC_vadar) # Returns a dataframe where the dates match (copies SECs larger bins over every cell in its date range)\n",
    "#Add in actual stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting to see trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "    # Train Test split for Neural Net\n",
    "X_train={}\n",
    "y_train={}\n",
    "X_test={}\n",
    "y_test={}\n",
    "for ticker in tickers:\n",
    "    X_train[ticker]=None #TODO\n",
    "    y_train[ticker]=None #TODO\n",
    "    X_test[ticker]=None #TODO\n",
    "    y_test[ticker]=None #TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Net\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "for ticker in tickers:\n",
    "    # Define the LSTM RNN model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Initial model setup\n",
    "    number_units = 30\n",
    "    dropout_fraction = 0.2\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(LSTM(\n",
    "        units=number_units,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train[ticker].shape[1], 1))\n",
    "        )\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(LSTM(units=number_units))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train[ticker], y_train[ticker], epochs=10, shuffle=False, batch_size=90, verbose=1)\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.evaluate(X_test[ticker], y_test[ticker], verbose=0)\n",
    "\n",
    "    # Make predictions using the testing data X_test\n",
    "    predicted = model.predict(X_test[ticker])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal Generation\n",
    "signals_df = {}\n",
    "for ticker in tickers:\n",
    "    signals_df[ticker]['Signal'] = None # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Back Testing\n",
    "for ticker in tickers:\n",
    "    # Set initial capital\n",
    "    initial_capital = float(100000)\n",
    "\n",
    "    # Set the share size\n",
    "    share_size = 500\n",
    "\n",
    "    # Buy a 500 share position when the dual moving average crossover Signal equals 1\n",
    "    # Otherwise, `Position` should be zero (sell)\n",
    "    signals_df[ticker]['Position'] = share_size * signals_df[ticker]['Signal']\n",
    "\n",
    "    # Determine the points in time where a 500 share position is bought or sold\n",
    "    signals_df[ticker]['Entry/Exit Position'] = signals_df[ticker]['Position'].diff()\n",
    "\n",
    "    # Multiply the close price by the number of shares held, or the Position\n",
    "    signals_df[ticker]['Portfolio Holdings'] = signals_df[ticker]['close'] * signals_df[ticker]['Position']\n",
    "\n",
    "    # Subtract the amount of either the cost or proceeds of the trade from the initial capital invested\n",
    "    signals_df[ticker]['Portfolio Cash'] = initial_capital - (signals_df[ticker]['close'] * signals_df[ticker]['Entry/Exit Position']).cumsum() \n",
    "\n",
    "    # Calculate the total portfolio value by adding the portfolio cash to the portfolio holdings (or investments)\n",
    "    signals_df[ticker]['Portfolio Total'] = signals_df[ticker]['Portfolio Cash'] + signals_df[ticker]['Portfolio Holdings']\n",
    "\n",
    "    # Calculate the portfolio daily returns\n",
    "    signals_df[ticker]['Portfolio Daily Returns'] = signals_df[ticker]['Portfolio Total'].pct_change()\n",
    "\n",
    "    # Calculate the portfolio cumulative returns\n",
    "    signals_df[ticker]['Portfolio Cumulative Returns'] = (1 + signals_df[ticker]['Portfolio Daily Returns']).cumprod() - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Backtest\n",
    "\n",
    "# Visualize exit position relative to total portfolio value\n",
    "exit = signals_df[signals_df['Entry/Exit'] == -1.0]['Portfolio Total'].hvplot.scatter(\n",
    "    color='yellow',\n",
    "    marker='v',\n",
    "    legend=False,\n",
    "    ylabel='Total Portfolio Value',\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Visualize entry position relative to total portfolio value\n",
    "entry = signals_df[signals_df['Entry/Exit'] == 1.0]['Portfolio Total'].hvplot.scatter(\n",
    "    color='purple',\n",
    "    marker='^',\n",
    "    ylabel='Total Portfolio Value',\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Visualize the value of the total portfolio\n",
    "total_portfolio_value = signals_df[['Portfolio Total']].hvplot(\n",
    "    line_color='lightgray',\n",
    "    ylabel='Total Portfolio Value',\n",
    "    xlabel='Date',\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Overlay the plots\n",
    "portfolio_entry_exit_plot = total_portfolio_value * entry * exit\n",
    "portfolio_entry_exit_plot.opts(\n",
    "    title=\"Apple Algorithm - Total Portfolio Value\",\n",
    "    yformatter='%.0f'\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60051db9b49e7622da472558d5c9910b644d729726c3e885e40a692d81c6b654"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
