{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "import pmaw\n",
    "import newsapi\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from newsapi import NewsApiClient\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from libs.prep_methods import articles_pull, subreddit_pull, keyword_filter, articles_vader_analyzer, reddit_vader_analyzer, daily_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsapi_key = os.getenv('NEWSAPI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple_articles = articles_pull('AAPL OR Apple OR apple')\n",
    "#apple_articles.to_csv('./Data/Cleaned_Data/apple_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple_articles = articles_pull('AAPL OR Apple OR apple')\n",
    "#apple_articles.to_csv('./Data/Cleaned_Data/apple_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple_articles = pd.read_csv('./Data/Cleaned_Data/apple_articles.csv', parse_dates = True, infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apple_articles_sentiment = daily_mean('articles', articles_vader_analyzer(apple_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after = int(dt.datetime(2012, 1, 1, 0, 0).timestamp())\n",
    "#before = int(dt.datetime(2022, 6, 1, 0, 0).timestamp())\n",
    "\n",
    "#stockmarket_comments = subreddit_pull('stockmarket', limit = 10000, after = after, before = before)\n",
    "#stockmarket_comments.to_csv('./Data/Cleaned_Data/stockmarket_comments.csv')\n",
    "\n",
    "#securityanalysis_comments = subreddit_pull('securityanalysis', limit = 2000000, after = after, before = before)\n",
    "#securityanalysis_comments.to_csv('../../sandbox/securityanalysis_comments_large.csv')\n",
    "\n",
    "#algotrading_comments = subreddit_pull('algotrading', limit = 10000, after = after, before = before)\n",
    "#algotrading_comments.to_csv('./Data/Cleaned_Data/algotrading_comments.csv')\n",
    "\n",
    "#wallstreetbets_comments = subreddit_pull('wallstreetbets', limit = 2000000, after = after, before = before)\n",
    "#wallstreetbets_comments.to_csv('.../../sandbox/wallstreetbets_comments_large.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_comments = pd.read_csv('../../sandbox/stockmarket_comments_large.csv', lineterminator = '\\n', parse_dates = True, infer_datetime_format = True)\n",
    "#securityanalysis_comments = pd.read_csv('../../sandbox/securityanalysis_comments_large.csv', lineterminator = '\\n', parse_dates = True, infer_datetime_format = True)\n",
    "#algotrading_comments = pd.read_csv('./Data/Cleaned_Data/algotrading_comments.csv')\n",
    "#wallstreetbets_comments = pd.read_csv('./Data/Cleaned_Data/wallstreetbets_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_airbnb_comments = keyword_filter(stockmarket_comments.fillna(''), ['ABNB', 'AirBNB', 'airbnb', 'Airbnb'])\n",
    "#stockmarket_uber_comments = keyword_filter(stockmarket_comments, ['UBER', 'Uber'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2r/54ybpmt959bcvp_5g8kfp3x40000gp/T/ipykernel_19071/3781093047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdaily_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreddit_vader_analyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stockmarket'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstockmarket_airbnb_comments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'coerce'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstockmarket_airbnb_daily_sentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data/Cleaned_Data/airbnb_sentiment.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/Penn_Fintech/P2G2-ProjectGit/Notebooks/libs/prep_methods.py\u001b[0m in \u001b[0;36mreddit_vader_analyzer\u001b[0;34m(subreddit, df)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{subreddit}_compound_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{subreddit}_positive_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{subreddit}_neutral_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Programming/Penn_Fintech/P2G2-ProjectGit/Notebooks/libs/prep_methods.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0manalyzer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentIntensityAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{subreddit}_compound_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compound'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{subreddit}_positive_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{subreddit}_neutral_sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'neu'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36mpolarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    360\u001b[0m         \u001b[0;31m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         sentitext = SentiText(\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREGEX_REMOVE_PUNCTUATION\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         )\n\u001b[1;32m    364\u001b[0m         \u001b[0msentiments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREGEX_REMOVE_PUNCTUATION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregex_remove_punctuation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords_and_emoticons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_and_emoticons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;31m# doesn't separate words from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# adjacent punctuation (keeps emoticons & contractions)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m_words_and_emoticons\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \"\"\"\n\u001b[1;32m    305\u001b[0m         \u001b[0mwes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_words_plus_punc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m         \u001b[0mwes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mwe\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m_words_plus_punc\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mwords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_only\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# the product gives ('cat', ',') and (',', 'cat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mpunc_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mpunc_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/nltk/sentiment/vader.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mwords_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_only\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;31m# the product gives ('cat', ',') and (',', 'cat')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0mpunc_before\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mpunc_after\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPUNC_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mwords_punc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpunc_before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stockmarket_airbnb_daily_sentiment = daily_mean(reddit_vader_analyzer('stockmarket', stockmarket_airbnb_comments))\n",
    "stockmarket_airbnb_daily_sentiment['datetime'] = pd.to_datetime(stockmarket_airbnb_daily_sentiment['datetime'], infer_datetime_format = True, errors = 'coerce')\n",
    "stockmarket_airbnb_daily_sentiment = stockmarket_airbnb_daily_sentiment.set_index('datetime')\n",
    "stockmarket_airbnb_daily_sentiment.index = stockmarket_airbnb_daily_sentiment.index.date\n",
    "stockmarket_airbnb_daily_sentiment.to_csv('./Data/Cleaned_Data/airbnb_sentiment.csv')\n",
    "\n",
    "stockmarket_uber_daily_sentiment = daily_mean(reddit_vader_analyzer('stockmarket', stockmarket_uber_comments))\n",
    "stockmarket_uber_daily_sentiment['datetime'] = pd.to_datetime(stockmarket_uber_daily_sentiment['datetime'], infer_datetime_format = True, errors = 'coerce')\n",
    "stockmarket_uber_daily_sentiment = stockmarket_uber_daily_sentiment.set_index('datetime')\n",
    "stockmarket_uber_daily_sentiment.index = stockmarket_uber_daily_sentiment.index.date\n",
    "stockmarket_uber_daily_sentiment.to_csv('./Data/Cleaned_Data/uber_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_airbnb_daily_sentiment = pd.read_csv('./Data/Cleaned_Data/airbnb_sentiment.csv', index_col = 0, lineterminator = '\\n', parse_dates = True, infer_datetime_format = True)\n",
    "stockmarket_uber_daily_sentiment = pd.read_csv('./Data/Cleaned_Data/uber_sentiment.csv', index_col = 0, lineterminator = '\\n', parse_dates = True, infer_datetime_format = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = pd.read_csv('./Data/Cleaned_Data/stock_data.csv', parse_dates = True, infer_datetime_format = True)\n",
    "stock_data['date'] = pd.to_datetime(stock_data['date'], infer_datetime_format = True, errors = 'coerce')\n",
    "stock_data = stock_data.set_index('date')\n",
    "stock_data.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_prices_volume = stock_data[stock_data['ticker'] == 'ABNB'].drop(columns = 'ticker')\n",
    "uber_prices_volume = stock_data[stock_data['ticker'] == 'UBER'].drop(columns = 'ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-10</th>\n",
       "      <td>144.71</td>\n",
       "      <td>70470750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-11</th>\n",
       "      <td>139.25</td>\n",
       "      <td>26981241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-14</th>\n",
       "      <td>130.00</td>\n",
       "      <td>16966090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-15</th>\n",
       "      <td>124.80</td>\n",
       "      <td>10914466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-16</th>\n",
       "      <td>137.99</td>\n",
       "      <td>20410248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-25</th>\n",
       "      <td>110.40</td>\n",
       "      <td>6170197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-26</th>\n",
       "      <td>114.30</td>\n",
       "      <td>6884206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-27</th>\n",
       "      <td>120.50</td>\n",
       "      <td>7375113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05-31</th>\n",
       "      <td>120.87</td>\n",
       "      <td>9089352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-01</th>\n",
       "      <td>116.72</td>\n",
       "      <td>6864663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             close    volume\n",
       "2020-12-10  144.71  70470750\n",
       "2020-12-11  139.25  26981241\n",
       "2020-12-14  130.00  16966090\n",
       "2020-12-15  124.80  10914466\n",
       "2020-12-16  137.99  20410248\n",
       "...            ...       ...\n",
       "2022-05-25  110.40   6170197\n",
       "2022-05-26  114.30   6884206\n",
       "2022-05-27  120.50   7375113\n",
       "2022-05-31  120.87   9089352\n",
       "2022-06-01  116.72   6864663\n",
       "\n",
       "[371 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb_prices_volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-02-14 22:09:46</td>\n",
       "      <td>The stock is making lower highers and lower lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-02-14 20:28:50</td>\n",
       "      <td>I wasn't accusing you of cherry picking. In fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-02-14 19:58:17</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-02-14 19:10:01</td>\n",
       "      <td>As others have said, the most important thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-14 18:55:25</td>\n",
       "      <td>Yup, that's it ... just in case you don't beli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994950</th>\n",
       "      <td>2021-01-27 18:55:10</td>\n",
       "      <td>No one's been \"scared away\", its been forcibly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994951</th>\n",
       "      <td>2021-01-27 18:55:10</td>\n",
       "      <td>They just updated it with a message....it's no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994952</th>\n",
       "      <td>2021-01-27 18:55:09</td>\n",
       "      <td>I predicted it would crash soon. Ugh. Should h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994953</th>\n",
       "      <td>2021-01-27 18:55:09</td>\n",
       "      <td>Don’t let them scare you, hold the line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994954</th>\n",
       "      <td>2021-01-27 18:55:06</td>\n",
       "      <td>“Power to the people! The whole world is watch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994955 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   datetime                                               text\n",
       "0       2015-02-14 22:09:46  The stock is making lower highers and lower lo...\n",
       "1       2015-02-14 20:28:50  I wasn't accusing you of cherry picking. In fa...\n",
       "2       2015-02-14 19:58:17                                          [deleted]\n",
       "3       2015-02-14 19:10:01  As others have said, the most important thing ...\n",
       "4       2015-02-14 18:55:25  Yup, that's it ... just in case you don't beli...\n",
       "...                     ...                                                ...\n",
       "994950  2021-01-27 18:55:10  No one's been \"scared away\", its been forcibly...\n",
       "994951  2021-01-27 18:55:10  They just updated it with a message....it's no...\n",
       "994952  2021-01-27 18:55:09  I predicted it would crash soon. Ugh. Should h...\n",
       "994953  2021-01-27 18:55:09            Don’t let them scare you, hold the line\n",
       "994954  2021-01-27 18:55:06  “Power to the people! The whole world is watch...\n",
       "\n",
       "[994955 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockmarket_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockmarket_compound_sentiment</th>\n",
       "      <th>stockmarket_positive_sentiment</th>\n",
       "      <th>stockmarket_neutral_sentiment</th>\n",
       "      <th>stockmarket_negative_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>0.344660</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.839400</td>\n",
       "      <td>0.051400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0.173927</td>\n",
       "      <td>0.129533</td>\n",
       "      <td>0.763933</td>\n",
       "      <td>0.106600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0.325671</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>0.910857</td>\n",
       "      <td>0.014571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>-0.065927</td>\n",
       "      <td>0.091727</td>\n",
       "      <td>0.826091</td>\n",
       "      <td>0.082182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0.937750</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.746500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-27</th>\n",
       "      <td>0.257559</td>\n",
       "      <td>0.113741</td>\n",
       "      <td>0.811407</td>\n",
       "      <td>0.074852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-28</th>\n",
       "      <td>-0.284950</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.850750</td>\n",
       "      <td>0.106250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-29</th>\n",
       "      <td>0.112631</td>\n",
       "      <td>0.086644</td>\n",
       "      <td>0.830378</td>\n",
       "      <td>0.082978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-01</th>\n",
       "      <td>0.206287</td>\n",
       "      <td>0.084250</td>\n",
       "      <td>0.873292</td>\n",
       "      <td>0.042417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            stockmarket_compound_sentiment  stockmarket_positive_sentiment  \\\n",
       "2013-01-01                        0.344660                        0.109400   \n",
       "2013-01-02                        0.173927                        0.129533   \n",
       "2013-01-03                        0.325671                        0.074571   \n",
       "2013-01-04                       -0.065927                        0.091727   \n",
       "2013-01-05                        0.937750                        0.253500   \n",
       "...                                    ...                             ...   \n",
       "2016-02-26                             NaN                             NaN   \n",
       "2016-02-27                        0.257559                        0.113741   \n",
       "2016-02-28                       -0.284950                        0.043000   \n",
       "2016-02-29                        0.112631                        0.086644   \n",
       "2016-03-01                        0.206287                        0.084250   \n",
       "\n",
       "            stockmarket_neutral_sentiment  stockmarket_negative_sentiment  \n",
       "2013-01-01                       0.839400                        0.051400  \n",
       "2013-01-02                       0.763933                        0.106600  \n",
       "2013-01-03                       0.910857                        0.014571  \n",
       "2013-01-04                       0.826091                        0.082182  \n",
       "2013-01-05                       0.746500                        0.000000  \n",
       "...                                   ...                             ...  \n",
       "2016-02-26                            NaN                             NaN  \n",
       "2016-02-27                       0.811407                        0.074852  \n",
       "2016-02-28                       0.850750                        0.106250  \n",
       "2016-02-29                       0.830378                        0.082978  \n",
       "2016-03-01                       0.873292                        0.042417  \n",
       "\n",
       "[1156 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockmarket_airbnb_daily_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb = pd.concat([stockmarket_airbnb_daily_sentiment, airbnb_prices_volume], join = 'outer', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stockmarket_compound_sentiment</th>\n",
       "      <th>stockmarket_positive_sentiment</th>\n",
       "      <th>stockmarket_neutral_sentiment</th>\n",
       "      <th>stockmarket_negative_sentiment</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [stockmarket_compound_sentiment, stockmarket_positive_sentiment, stockmarket_neutral_sentiment, stockmarket_negative_sentiment, close, volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airbnb.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('pyvizenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4aae7ae0ea0c990573bbc5423c43265214dd7797168b544b883b40c2ec9d805a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
