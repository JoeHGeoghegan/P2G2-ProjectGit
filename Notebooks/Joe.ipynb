{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joe's code place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Hackerman](https://i.kym-cdn.com/entries/icons/mobile/000/021/807/ig9OoyenpxqdCQyABmOQBZDI0duHk2QZZmWg2Hxd4ro.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Ticker Library init\\nportfolio = {'Sector':[],'Company Name':[],'Ticker':[]}\\nhello = [\\n    ['Technology','Netflix','NFLX'],\\n    ['Technology','Meta','FB'],\\n    ['Technology','Uber','UBER'],\\n    ['Technology','Microchip Technology','MCHP'],\\n    ['Technology','AirBnB','ABNB'],\\n    ['Energy','Diamondback Energy Inc.','FANG'],\\n    ['Energy','Marathon Oil Corp.','MRO'],\\n    ['Energy','Devon Energy Corp.','DVN'],\\n    ['Energy','SunPower Corp.','SPWR'],\\n    ['Energy','Renewable Energy Group Inc.','REGI'],\\n    ['Finance','McKinsey & Company','MTRX'],\\n    ['Finance','BlackRock','BLK'],\\n    ['Finance','PayPal','PYPL'],\\n    ['Finance','Mercadolibre Inc','MELI'],\\n    ['Finance','SoFi','SOFI']\\n]\\nfor row in hello:\\n    portfolio['Sector'].append(row[0])\\n    portfolio['Company Name'].append(row[1])\\n    portfolio['Ticker'].append(row[2])\\nportfolio = pd.DataFrame(portfolio).set_index('Sector')\\nportfolio.to_csv('./Data/Cleaned_Data/Ticker_library.csv')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Ticker Library init\n",
    "portfolio = {'Sector':[],'Company Name':[],'Ticker':[]}\n",
    "hello = [\n",
    "    ['Technology','Netflix','NFLX'],\n",
    "    ['Technology','Meta','FB'],\n",
    "    ['Technology','Uber','UBER'],\n",
    "    ['Technology','Microchip Technology','MCHP'],\n",
    "    ['Technology','AirBnB','ABNB'],\n",
    "    ['Energy','Diamondback Energy Inc.','FANG'],\n",
    "    ['Energy','Marathon Oil Corp.','MRO'],\n",
    "    ['Energy','Devon Energy Corp.','DVN'],\n",
    "    ['Energy','SunPower Corp.','SPWR'],\n",
    "    ['Energy','Renewable Energy Group Inc.','REGI'],\n",
    "    ['Finance','McKinsey & Company','MTRX'],\n",
    "    ['Finance','BlackRock','BLK'],\n",
    "    ['Finance','PayPal','PYPL'],\n",
    "    ['Finance','Mercadolibre Inc','MELI'],\n",
    "    ['Finance','SoFi','SOFI']\n",
    "]\n",
    "for row in hello:\n",
    "    portfolio['Sector'].append(row[0])\n",
    "    portfolio['Company Name'].append(row[1])\n",
    "    portfolio['Ticker'].append(row[2])\n",
    "portfolio = pd.DataFrame(portfolio).set_index('Sector')\n",
    "portfolio.to_csv('./Data/Cleaned_Data/Ticker_library.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_twitter_API():\n",
    "    return tweepy.API(\n",
    "        tweepy.OAuth1UserHandler(\n",
    "            # Generated when you setup your Twitter Dev account\n",
    "            os.getenv(\"twitter_api_consumer_key\"),\n",
    "            os.getenv(\"twitter_api_consumer_secret_key\"),\n",
    "            # You have to generate the below after you setup your Twitter Dev Account\n",
    "            os.getenv(\"twitter_api_access_key\"),\n",
    "            os.getenv(\"twitter_api_access_secret_key\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "# tw = init_twitter_API()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Edgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secedgar import CompanyFilings, FilingType\n",
    "\n",
    "def sec_filings(sec_filings, your_name, your_email, start, end, filing_type:FilingType=FilingType.FILING_10Q):\n",
    "    return CompanyFilings(cik_lookup=sec_filings,\n",
    "                                filing_type=filing_type,\n",
    "                                start_date=start,\n",
    "                                end_date=end,\n",
    "                                user_agent=f'{your_name} ({your_email})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = pd.read_csv('./Data/Cleaned_Data/Ticker_library.csv')['Ticker'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sec_edgar_downloader import Downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_SEC(path,tickers,filing_type,after_date,before_date=None):\n",
    "    dl = Downloader(f'{path}')\n",
    "    for ticker in tickers:\n",
    "        dl.get(filing_type, ticker, after=after_date,before=before_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_SEC('./Data/Raw_Data/',tickers,\"10-Q\",after_date='2012-06-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_html('.\\Data\\Raw_Data\\sec-edgar-filings\\ABNB/10-Q/0001559720-21-000017/full-submission.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_finder():\n",
    "    txts = []\n",
    "    for root, dirs, files in os.walk(\".\", topdown=False):\n",
    "        for name in files:\n",
    "            os.path.join(root, name)\n",
    "            # print(name)\n",
    "            if name[-4:]=='.txt':\n",
    "                txts.append(f'{root}/{name}')\n",
    "        for name in dirs:\n",
    "            os.path.join(root, name)\n",
    "    return txts\n",
    "sec_paths = txt_finder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\Data\\\\Raw_Data\\\\sec-edgar-filings\\\\ABNB\\\\10-Q\\\\0001559720-21-000017/full-submission.txt'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sec_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_part(path,before,after):\n",
    "    beforeNum = path.find(before)+len(before)\n",
    "    afterNum = path.find(after)\n",
    "    return path[beforeNum:afterNum]\n",
    "\n",
    "def sec_df_from_paths(sec_paths,filing_type):\n",
    "    data = {\n",
    "        'Ticker':[],\n",
    "        'DocName':[],\n",
    "        'DocText':[]\n",
    "    }\n",
    "    for sec in sec_paths:\n",
    "        data['Ticker'].append(path_part(sec,'sec-edgar-filings\\\\',f'\\\\{filing_type}'))\n",
    "        data['DocName'].append(path_part(sec,f'\\\\{filing_type}\\\\','/full-submission'))\n",
    "        \n",
    "        sec_txt = open(sec, \"r\")\n",
    "        data['DocText'] = sec_txt.read()\n",
    "        sec_txt.close()\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_10Q = sec_df_from_paths(sec_paths,'10-Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(df_10Q['DocText'].loc[0],'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "def html_clean(html_txt,loops=2): # This loops to make sure <*<*>*> and such are caught. (TODO might not work might catch <*<*> and miss the *>)\n",
    "    for loop in range(loops):\n",
    "        # removes <*>, {*}, and [*] from the HTML\n",
    "        html_txt = re.sub(\"[\\<\\{\\[].*?[\\>\\}\\]]\",\" \",html_txt)\n",
    "    return html_txt\n",
    "def soup_clean(html_txt):\n",
    "    return BeautifulSoup(html_txt, 'html.parser').get_text()\n",
    "df_10Q_Test = df_10Q.copy()\n",
    "# df_10Q_Test['DocText'] = [html_clean(txt) for txt in df_10Q_Test['DocText'].to_list()]\n",
    "df_10Q_Test['DocText'] = [soup_clean(txt) for txt in df_10Q_Test['DocText'].to_list()]\n",
    "df_10Q_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10Q_Test.to_csv('.\\Data\\Cleaned_Data\\sec_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRAW reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "60051db9b49e7622da472558d5c9910b644d729726c3e885e40a692d81c6b654"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
