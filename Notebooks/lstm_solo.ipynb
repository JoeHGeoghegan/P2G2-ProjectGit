{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key savefig.frameon in file /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 421 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 472 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 473 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.4.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/laurenkrohn/opt/anaconda3/envs/pyvizenv/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import math # Mathematical functions \n",
    "import numpy as np # Fundamental package for scientific computing with Python\n",
    "import pandas as pd # Additional functions for analysing and manipulating data\n",
    "from datetime import date, timedelta, datetime # Date Functions\n",
    "from pandas.plotting import register_matplotlib_converters # This function adds plotting functions for calender dates\n",
    "import matplotlib.pyplot as plt # Important package for visualization - we use this to plot the market data\n",
    "import matplotlib.dates as mdates # Formatting dates\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error # Packages for measuring model performance / errors\n",
    "from tensorflow.keras import Sequential # Deep learning library, used for neural networks\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout # Deep learning classes for recurrent and regular densely-connected layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping # EarlyStopping during model training\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler # This Scaler removes the median and scales the data according to the quantile range to normalize the price data \n",
    "import seaborn as sns # Visualization\n",
    "sns.set_style('white', { 'axes.spines.right': False, 'axes.spines.top': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sort_df(filepath):\n",
    "    df = pd.read_csv(f'{filepath}', parse_dates = True, infer_datetime_format = True)\n",
    "    df['Unnamed: 0'] = pd.to_datetime(df['Unnamed: 0'], infer_datetime_format = True, errors = 'coerce', format = '%Y/%m/%d')\n",
    "    df = df.set_index('Unnamed: 0')\n",
    "    df.index.name = None\n",
    "    df = df.reset_index().rename({'index': 'date'}, axis=1)\n",
    "    train_df = df.sort_values(by=['date']).copy()\n",
    "    train_df = train_df.set_index('date')\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_df = load_sort_df('../Notebooks/Data/Cleaned_Data/FB.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sec_compound_sentiment', 'sec_positive_sentiment',\n",
      "       'sec_neutral sentiment', 'sec_negative_sentiment',\n",
      "       'stockmarket_compound_sentiment', 'stockmarket_positive_sentiment',\n",
      "       'stockmarket_neutral_sentiment', 'stockmarket_negative_sentiment',\n",
      "       'volume', 'close'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(fb_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sentiment = [#'sec_compound_sentiment',\n",
    "                    'sec_positive_sentiment',\n",
    "                    'sec_neutral sentiment',\n",
    "                    'sec_negative_sentiment',\n",
    "                    'stockmarket_compound_sentiment',\n",
    "                    'stockmarket_positive_sentiment',\n",
    "                    'stockmarket_neutral_sentiment',\n",
    "                    'stockmarket_negative_sentiment',\n",
    "                    'volume',\n",
    "                    'close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm(train_df, features):\n",
    "    # Create the dataset with features and filter the data to the list of FEATURES\n",
    "    data = pd.DataFrame(train_df)\n",
    "    data_filtered = data[features]\n",
    "\n",
    "    # We add a prediction column and set dummy values to prepare the data for scaling\n",
    "    data_filtered_ext = data_filtered.copy()\n",
    "    data_filtered_ext['Prediction'] = data_filtered_ext['close']\n",
    "\n",
    "    # Print the tail of the dataframe\n",
    "    data_filtered_ext.tail()\n",
    "\n",
    "    # Scaling\n",
    "    # Convert the data to numpy values\n",
    "    np_data_unscaled = np.array(data_filtered)\n",
    "\n",
    "    # Transform the data by scaling each feature to a range between 0 and 1\n",
    "    scaler = MinMaxScaler()\n",
    "    np_data_scaled = scaler.fit_transform(np_data_unscaled)\n",
    "\n",
    "    # Set the sequence length - this is the timeframe used to make a single prediction\n",
    "    sequence_length = \"50\"\n",
    "\n",
    "    # Prediction Index\n",
    "    index_Close = data_filtered.columns.get_loc(\"close\")\n",
    "\n",
    "    # Split the training data into train and train data sets\n",
    "    # As a first step, we get the number of rows to train the model on 80% of the data \n",
    "    train_data_len = math.ceil(np_data_scaled.shape[0] * 0.8)\n",
    "\n",
    "    # Create the training and test data\n",
    "    train_data = np_data_scaled[0:train_data_len, :]\n",
    "    test_data = np_data_scaled[train_data_len - sequence_length:, :]\n",
    "\n",
    "    # The RNN needs data with the format of [samples, time steps, features]\n",
    "    # Here, we create N samples, sequence_length time steps per sample, and 6 features\n",
    "    def partition_dataset(sequence_length, data):\n",
    "        x, y = [], []\n",
    "        data_len = data.shape[0]\n",
    "        for i in range(sequence_length, data_len):\n",
    "            x.append(data[i-sequence_length:i,:]) #contains sequence_length values 0-sequence_length * columns\n",
    "            y.append(data[i, index_Close]) #contains the prediction values for validation,  for single-step prediction\n",
    "    \n",
    "        # Convert the x and y to numpy arrays\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "        return x, y\n",
    "\n",
    "    # Generate training data and test data\n",
    "    x_train, y_train = partition_dataset(sequence_length, train_data)\n",
    "    x_test, y_test = partition_dataset(sequence_length, test_data)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_30641/4180802423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepare_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfb_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/d9/6r5nm8y56sbbg2kbt5s3pxhr0000gn/T/ipykernel_30641/3277013797.py\u001b[0m in \u001b[0;36mprepare_lstm\u001b[0;34m(train_df, features)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Create the training and test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_data_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain_data_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_data_scaled\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_data_len\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# The RNN needs data with the format of [samples, time steps, features]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "prepare_lstm(fb_df, feature_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "391e0d32ac29f228a6e855b7fe4b361ee8a8f8d43143222036cbf0ccc87e93d7"
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 ('pyvizenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
