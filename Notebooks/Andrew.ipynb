{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "985386aa-2faf-48f7-861f-4a19037ca0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\altma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import datetime as dt\n",
    "import alpaca_trade_api as tradeapi\n",
    "import json\n",
    "from alpaca_trade_api.rest import REST, TimeFrame\n",
    "from libs.drew_lib import *\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "517496b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpaca_key = os.getenv(\"ALPACA_API_KEY\")\n",
    "alpaca_secret_key = os.getenv(\"ALPACA_SECRET_KEY\")\n",
    "\n",
    "tradeapi = REST(alpaca_key, alpaca_secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a25fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_keywords = {\n",
    "    'NFLX': ['NFLX', 'nflx', 'Netflix', 'netflix'],\n",
    "    'FB': ['FB', 'fb', 'Facebook', 'facebook'],\n",
    "    'UBER': ['UBER', 'uber', 'Uber'],\n",
    "    'MCHP': ['MCHP', 'mchp', 'Microchip Technology'],\n",
    "    'ABNB': ['ABNB', 'abnb', 'AirBnB', 'airbnb'],\n",
    "    'FANG': ['FANG', 'fang', 'Diamondback Energy', 'diamondback energy', 'Diamondback', 'diamondback'],\n",
    "    'MRO': ['MRO', 'mro', 'Marathon Oil', 'marathon oil'],\n",
    "    'DVN': ['DVN', 'dvn', 'Devon Energy', 'devon energy'],\n",
    "    'SPWR': ['SPWR', 'spwr', 'SunPower', 'Sunpower', 'sunpower'],\n",
    "    'REGI': ['REGI', 'regi', 'Renewable Energy Group', 'renewable energy group'],\n",
    "    'MTRX': ['MTRX', 'mtrx', 'McKinsey & Company', 'McKinsey & Co', 'Mckinsey & Co', 'McKinsey', 'Mckinsey', 'mckinsey'],\n",
    "    'BLK': ['BLK', 'blk', 'BlackRock', 'Blackrock', 'blackrock'],\n",
    "    'PYPL': ['PYPL', 'pypl', 'PayPal', 'Paypal', 'paypal'],\n",
    "    'MELI': ['MELI', 'meli', 'MercadoLibre', 'Mercadolibre', 'mercadolibre'],\n",
    "    'SOFI': ['SOFI', 'sofi', 'SoFi', 'Sofi']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49aa0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_daily_trade_data(ticker, start, end, tradeapi): \n",
    "#     ticker_df = tradeapi.get_bars(\n",
    "#         ticker,\n",
    "#         TimeFrame.Day,\n",
    "#         start,\n",
    "#         end\n",
    "#     ).df\n",
    "#     ticker_df['ticker'] = ticker\n",
    "\n",
    "#     return ticker_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2759568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list = pd.read_csv('./Data/Cleaned_Data/Ticker_library.csv')['Ticker'].to_list()\n",
    "\n",
    "# def make_tickers_df(ticker_list, start_date_str, end_date_str, tradeapi):\n",
    "#     ticker_dfs_list = [get_daily_trade_data(ticker, start_date_str, end_date_str, tradeapi) for ticker in ticker_list]\n",
    "#     tickers_df = pd.concat(ticker_dfs_list, axis=0, join='outer')\n",
    "#     tickers_df.index = tickers_df.index.date\n",
    "#     tickers_df = tickers_df[['ticker','close','volume']]\n",
    "#     return tickers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b29b7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_tickers_dict(ticker_list, start_date_str, end_date_str, tradeapi):\n",
    "#     return {ticker: get_daily_trade_data(ticker, start_date_str, end_date_str, tradeapi) for ticker in ticker_list}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e9e5c",
   "metadata": {},
   "source": [
    "## News Article Vader Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f81f1ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\altma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from libs.drew_lib import *\n",
    "\n",
    "from newsapi import NewsApiClient\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7ba719c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "api_key = os.getenv(\"NEWSAPI_KEY\")\n",
    "newsapi = NewsApiClient(api_key=api_key)\n",
    "print(type(api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cbf3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_df = pd.read_csv('./Data/Cleaned_Data/Ticker_library.csv')\n",
    "# company_df = company_df.rename(columns={'Company Name': 'Company_Name'})\n",
    "# company_dict = dict(zip(company_df.Company_Name, company_df.Ticker))\n",
    "# company_list = list(company_dict.keys())\n",
    "# tickers_list = company_dict.values()\n",
    "# ls = [type(item) for item in company_list]\n",
    "# print(ls)\n",
    "# tickers_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a7bbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_analyzer(df):\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df['compound'] = [analyzer.polarity_scores(x)['compound'] for x in df['text']]\n",
    "    df['neg'] = [analyzer.polarity_scores(x)['neg'] for x in df['text']]\n",
    "    df['neu'] = [analyzer.polarity_scores(x)['neu'] for x in df['text']]\n",
    "    df['pos'] = [analyzer.polarity_scores(x)['pos'] for x in df['text']]\n",
    "\n",
    "    df['date'] = pd.to_datetime(\n",
    "    df['date'],\n",
    "    infer_datetime_format = True,\n",
    "    utc = True    \n",
    "    )\n",
    "    df['date'] = df['date'].dt.date\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb7d03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\2360381749.py:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  news_sent_avg = vader_news_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>0.075167</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.898667</td>\n",
       "      <td>0.199033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.631000</td>\n",
       "      <td>0.491200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>0.169000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>0.709950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.952000</td>\n",
       "      <td>-0.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2022-05-20</td>\n",
       "      <td>UBER</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>-0.759900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2022-05-24</td>\n",
       "      <td>UBER</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0660</td>\n",
       "      <td>0.934000</td>\n",
       "      <td>-0.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2022-05-25</td>\n",
       "      <td>UBER</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>-0.128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2022-06-06</td>\n",
       "      <td>UBER</td>\n",
       "      <td>0.053000</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.159100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2022-06-07</td>\n",
       "      <td>UBER</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.978500</td>\n",
       "      <td>0.084000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date ticker       pos     neg       neu  compound\n",
       "0    2022-05-11   ABNB  0.075167  0.0260  0.898667  0.199033\n",
       "1    2022-05-12   ABNB  0.210000  0.1590  0.631000  0.491200\n",
       "2    2022-05-14   ABNB  0.169000  0.0000  0.831000  0.709950\n",
       "3    2022-05-16   ABNB  0.000000  0.0000  1.000000  0.000000\n",
       "4    2022-05-18   ABNB  0.000000  0.0480  0.952000 -0.278700\n",
       "..          ...    ...       ...     ...       ...       ...\n",
       "182  2022-05-20   UBER  0.000000  0.1770  0.823000 -0.759900\n",
       "183  2022-05-24   UBER  0.000000  0.0660  0.934000 -0.296000\n",
       "184  2022-05-25   UBER  0.000000  0.0400  0.960000 -0.128000\n",
       "185  2022-06-06   UBER  0.053000  0.0485  0.898000  0.159100\n",
       "186  2022-06-07   UBER  0.021500  0.0000  0.978500  0.084000\n",
       "\n",
       "[187 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_list = [form_df(company) for company in company_list]\n",
    "news_df = pd.concat(news_df_list, axis=0, join='outer')\n",
    "vader_news_df = vader_analyzer(news_df)\n",
    "news_sent_avg = vader_news_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
    "news_sent_avg = news_sent_avg[['date','ticker','pos','neg','neu','compound']]\n",
    "news_sent_avg\n",
    "\n",
    "#news_sent_avg.to_csv('../Notebooks/Data/Cleaned_Data/news_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c18d9a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
      "C:\\Users\\altma\\AppData\\Local\\Temp\\ipykernel_42908\\606697139.py:5: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>pos</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-08</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.064000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936000</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.074333</td>\n",
       "      <td>0.044667</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>0.189467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.475300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.361200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date ticker       pos       neg       neu  compound\n",
       "0  2022-05-08   NFLX  0.064000  0.000000  0.936000  0.340000\n",
       "1  2022-05-09   NFLX  0.000000  0.000000  1.000000  0.000000\n",
       "2  2022-05-10   NFLX  0.074333  0.044667  0.881333  0.189467\n",
       "3  2022-05-13   NFLX  0.110000  0.000000  0.890000  0.475300\n",
       "4  2022-05-14   NFLX  0.077000  0.000000  0.923000  0.361200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df_list = [form_df(company) for company in company_list]\n",
    "vader_news_df_list = [daily_sentiment(df) for df in news_df_list]\n",
    "vader_news_df = pd.concat(vader_news_df_list, axis=0, join='outer')\n",
    "vader_news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d71c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform sentiment analysis and find average sentiment by date\n",
    "\n",
    "def daily_sentiment(df):\n",
    "    vader_df = vader_analyzer(df)\n",
    "    vader_df = vader_df.groupby(['ticker','date'])['ticker','pos','neg','neu','compound'].mean().reset_index()\n",
    "    vader_df = vader_df[['date','ticker','pos','neg','neu','compound']]\n",
    "    return vader_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f16d4ca",
   "metadata": {},
   "source": [
    "## Helper Functions for PuttingItTogether"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8253e740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_bin(df):\n",
    "\n",
    "    bins = [-1000, -0.08, -0.03, -0.0000001, 0.0000001, 0.03, 0.08, 1000]\n",
    "    labels = ['large loss','medium loss','small loss','no gain/loss','small gain','medium gain','large gain']\n",
    "    \n",
    "    df['returns'] = df['close'].pct_change()\n",
    "    df['return_bin'] = pd.cut(df['returns'], bins=bins, labels=labels)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ff48b0",
   "metadata": {},
   "source": [
    "## Data prep for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35efcb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "681af540",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'date' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\altma\\OneDrive\\Documents\\FinTechBootCamp\\projects\\P2G2-ProjectGit\\Notebooks\\Andrew.ipynb Cell 18'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000025?line=0'>1</a>\u001b[0m nflx_df \u001b[39m=\u001b[39m stock_picker(\u001b[39m'\u001b[39;49m\u001b[39mNFLX\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000025?line=1'>2</a>\u001b[0m nflx_df \u001b[39m=\u001b[39m return_bin(nflx_df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000025?line=2'>3</a>\u001b[0m nflx_df \u001b[39m=\u001b[39m nflx_df[nflx_df[\u001b[39m'\u001b[39m\u001b[39mreturn_bin\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mnotna()]\n",
      "\u001b[1;32mc:\\Users\\altma\\OneDrive\\Documents\\FinTechBootCamp\\projects\\P2G2-ProjectGit\\Notebooks\\Andrew.ipynb Cell 14'\u001b[0m in \u001b[0;36mstock_picker\u001b[1;34m(ticker)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000021?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(file_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000021?line=8'>9</a>\u001b[0m     \u001b[39mif\u001b[39;00m filename\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m filename \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mTicker_library.csv\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000021?line=9'>10</a>\u001b[0m         csv_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(file_path \u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49m filename, parse_dates\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, infer_datetime_format\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,index_col\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000021?line=10'>11</a>\u001b[0m         csv_df \u001b[39m=\u001b[39m csv_df\u001b[39m.\u001b[39mloc[csv_df[\u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m ticker]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000021?line=11'>12</a>\u001b[0m         csv_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mticker\u001b[39m\u001b[39m'\u001b[39m,axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1231\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1227'>1228</a>\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n\u001b[0;32m   <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1229'>1230</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1230'>1231</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1231'>1232</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/readers.py?line=1232'>1233</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:153\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=150'>151</a>\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=151'>152</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_parse_dates_presence(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=152'>153</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_noconvert_columns()\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=154'>155</a>\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=155'>156</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morig_names \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:208\u001b[0m, in \u001b[0;36mCParserWrapper._set_noconvert_columns\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=205'>206</a>\u001b[0m col_indices \u001b[39m=\u001b[39m [names_dict[x] \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames]  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=206'>207</a>\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=207'>208</a>\u001b[0m noconvert_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_noconvert_dtype_columns(\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=208'>209</a>\u001b[0m     col_indices,\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=209'>210</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnames,  \u001b[39m# type: ignore[has-type]\u001b[39;49;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=210'>211</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=211'>212</a>\u001b[0m \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m noconvert_columns:\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=212'>213</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39mset_noconvert(col)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:673\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns\u001b[1;34m(self, col_indices, names)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=670'>671</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=671'>672</a>\u001b[0m     \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col:\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=672'>673</a>\u001b[0m         noconvert_columns\u001b[39m.\u001b[39madd(_set(k))\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=673'>674</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=674'>675</a>\u001b[0m     noconvert_columns\u001b[39m.\u001b[39madd(_set(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_col))\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:650\u001b[0m, in \u001b[0;36mParserBase._set_noconvert_dtype_columns.<locals>._set\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=646'>647</a>\u001b[0m     x \u001b[39m=\u001b[39m usecols[x]\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=648'>649</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(x):\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=649'>650</a>\u001b[0m     x \u001b[39m=\u001b[39m col_indices[names\u001b[39m.\u001b[39;49mindex(x)]\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/pandas/io/parsers/base_parser.py?line=651'>652</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "\u001b[1;31mValueError\u001b[0m: 'date' is not in list"
     ]
    }
   ],
   "source": [
    "nflx_df = stock_picker('NFLX')\n",
    "nflx_df = return_bin(nflx_df)\n",
    "nflx_df = nflx_df[nflx_df['return_bin'].notna()]\n",
    "nflx_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26acce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = nflx_df.copy()\n",
    "X = nflx_df.drop(columns=['return_bin','ticker'])\n",
    "y = nflx_df['return_bin'].values\n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b834b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816a27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler()\n",
    "X_scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14bcd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder()\n",
    "enc.fit(y_train)\n",
    "\n",
    "y_train_enc = enc.transform(y_train).toarray()\n",
    "y_test_enc = enc.transform(y_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12325bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12b0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "14/14 [==============================] - 3s 7ms/step - loss: nan\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 0s 8ms/step - loss: nan\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 0s 6ms/step - loss: nan\n"
     ]
    }
   ],
   "source": [
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_scaled.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train_enc, epochs=20, shuffle=False, batch_size=90, verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "model.evaluate(X_test_scaled, y_test_enc, verbose=0)\n",
    "\n",
    "# Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905687ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\altma\\OneDrive\\Documents\\FinTechBootCamp\\projects\\P2G2-ProjectGit\\Notebooks\\Andrew.ipynb Cell 33'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000063?line=0'>1</a>\u001b[0m predicted \u001b[39m=\u001b[39m enc\u001b[39m.\u001b[39;49minverse_transform(predicted)\u001b[39m.\u001b[39mflatten()\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000063?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000063?line=2'>3</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mActual\u001b[39m\u001b[39m\"\u001b[39m: y_test\u001b[39m.\u001b[39mactivity\u001b[39m.\u001b[39mvalues,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000063?line=3'>4</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mPredicted\u001b[39m\u001b[39m\"\u001b[39m: predicted\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000063?line=4'>5</a>\u001b[0m })\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/altma/OneDrive/Documents/FinTechBootCamp/projects/P2G2-ProjectGit/Notebooks/Andrew.ipynb#ch0000063?line=5'>6</a>\u001b[0m results\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:582\u001b[0m, in \u001b[0;36mOneHotEncoder.inverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=561'>562</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=562'>563</a>\u001b[0m \u001b[39mConvert the data back to the original representation.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=563'>564</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=578'>579</a>\u001b[0m \u001b[39m    Inverse transformed array.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=579'>580</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=580'>581</a>\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=581'>582</a>\u001b[0m X \u001b[39m=\u001b[39m check_array(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=583'>584</a>\u001b[0m n_samples, _ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/preprocessing/_encoders.py?line=584'>585</a>\u001b[0m n_features \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcategories_)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=793'>794</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=794'>795</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=795'>796</a>\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=796'>797</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=798'>799</a>\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=799'>800</a>\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=801'>802</a>\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=802'>803</a>\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Users\\altma\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=107'>108</a>\u001b[0m         allow_nan\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=108'>109</a>\u001b[0m         \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misinf(X)\u001b[39m.\u001b[39many()\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=109'>110</a>\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=110'>111</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(X)\u001b[39m.\u001b[39mall()\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=111'>112</a>\u001b[0m     ):\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=112'>113</a>\u001b[0m         type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minfinity\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m allow_nan \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNaN, infinity\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=113'>114</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=114'>115</a>\u001b[0m             msg_err\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=115'>116</a>\u001b[0m                 type_err, msg_dtype \u001b[39mif\u001b[39;00m msg_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=116'>117</a>\u001b[0m             )\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=117'>118</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=118'>119</a>\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/altma/anaconda3/lib/site-packages/sklearn/utils/validation.py?line=119'>120</a>\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "predicted = enc.inverse_transform(predicted).flatten().tolist()\n",
    "results = pd.DataFrame({\n",
    "    \"Actual\": y_test.activity.values,\n",
    "    \"Predicted\": predicted\n",
    "})\n",
    "results.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7e569e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f688966fe16c5b1d1f8096f0874425497eb397fd30a583fa64973664e1f67766"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
